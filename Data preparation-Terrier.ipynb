{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT (and other transformer methods) for IR - Data preparation\n",
    "\n",
    "This notebook covers the basic on how to implement a nice pipeline for training and running inference over a IR dataset.\n",
    "We wil use Anserini, with PySerini, to index and retrieve documents over the MsMarco TREC 2019 DL dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dependencies installation\n",
    "First, let's install whÂ§at we need. I highly recommend using something like Conda to manage your environment!\n",
    "\n",
    "We are using Python 3.7 and Cuda 10.1 (If you are using another version, check how to install Pytorch on https://pytorch.org/get-started/locally/#start-locally)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T00:43:24.023779Z",
     "start_time": "2020-04-02T00:43:20.965812Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "! conda install -y pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
    "# ðŸ¤— tokenizer (this gives us A HUGE boost on performance. Tokenizing is the slowest part of the process)\n",
    "! pip install tokenizer\n",
    "# ðŸ¤— Transformer\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T00:43:25.717718Z",
     "start_time": "2020-04-02T00:43:25.599407Z"
    }
   },
   "source": [
    "### Anserini installation.\n",
    "Java is a pain in the ass. That's why you should run these commands on your terminal, not here!\n",
    "\n",
    "```git clone https://github.com/castorini/anserini`\n",
    "curl -s \"https://get.sdkman.io\" | bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "sdk install java\n",
    "sdk use java 11.0.6.hs-adpt # This may change. Check the version of Java 11 that were installed\n",
    "cd anserini\n",
    "mvn clean package -Dmaven.test.skip=true appassembler:assemble\n",
    "```\n",
    "\n",
    "This should be enough to install anserini. If not, check their repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local variables\n",
    "These variables are local to you, and should be eddited accordingly. thinks like path to download the dataset are all set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T22:15:22.216077Z",
     "start_time": "2020-04-16T22:15:22.209657Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_home = \"/ssd2/arthur/MsMarcoTREC/\"  # Where you want to store the docs\n",
    "anserini_path = \"/ssd2/arthur/bert4IR/anserini\"  # Should be where you downloaded and installed Anserini. Check above!\n",
    "n_threads = 32  # Number of threads to use. Make sure you have more than the number here!\n",
    "\n",
    "\n",
    "def get_path(x):\n",
    "    return os.path.join(data_home, x)\n",
    "\n",
    "\n",
    "if not os.path.isdir(data_home):\n",
    "    os.makedirs(data_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "We are using the MsMarco TREC 2019 dataset. We should download everything here.\n",
    "\n",
    "If you are running this from the DeepIR machine from WIS, we already have everything there. Ask Arthur where this is and `ln -s` to your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T22:15:28.331511Z",
     "start_time": "2020-04-16T22:15:28.315989Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "download_path = \"https://msmarco.blob.core.windows.net/msmarcoranking/\"  # default MsMarco path for downloading data\n",
    "# It sucks to need documents in both .trec and .tsv, but it's easier this way, believe me.\n",
    "files_to_get = [\n",
    "    \"docs/msmarco-docs.trec\",  #docs in trec format\n",
    "    \"docs/msmarco-docs.tsv\",  # docs in tsv format\n",
    "    \"queries/msmarco-doctrain-queries.tsv\",  # train queries\n",
    "    \"qrels/msmarco-doctrain-qrels.tsv\",  # train qrels\n",
    "    \"queries/msmarco-docdev-queries.tsv\",  # dev queries\n",
    "    \"qrels/msmarco-docdev-qrels.tsv\",  # dev qrels\n",
    "    \"queries/msmarco-test2019-queries.tsv\",  # test queries\n",
    "    \"qrels/2019qrels-docs.txt\"  # test qrels\n",
    "]\n",
    "for file in files_to_get:\n",
    "    local_file_path = get_path(file)\n",
    "    if not os.path.isfile(local_file_path):\n",
    "        print(\n",
    "            f\"File {file.split('/')[-1]} not found. Downloading it from the Web\"\n",
    "        )\n",
    "        url_to_fetch_from = download_path + file.split(\"/\")[1] + \".gz\"\n",
    "        # qrels for test comes from NIST, not from Microsoft. Also, no need to uncompress\n",
    "        if file == \"qrels/2019qrels-docs.txt\":\n",
    "            url_to_fetch_from = \"https://trec.nist.gov/data/deep/2019qrels-docs.txt\"\n",
    "            request.urlretrieve(url_to_fetch_from, local_file_path)\n",
    "            continue\n",
    "        # Create dir if it doesn't exist\n",
    "        if not os.path.isdir(\"/\".join(local_file_path.split(\"/\")[:-1])):\n",
    "            os.makedirs(\"/\".join(local_file_path.split(\"/\")[:-1]))\n",
    "        try:\n",
    "            request.urlretrieve(url_to_fetch_from, local_file_path + \".gz\")\n",
    "        except:\n",
    "            print(\n",
    "                f\"Could not fetch {file} from {url_to_fetch_from}. Make sure that's the right URL!\"\n",
    "            )\n",
    "            continue\n",
    "        #Uncompress file. Not needed, but easier. (you could use the gzip lib to open the files...)\n",
    "        with gzip.open(local_file_path + \".gz\", 'rb') as f_in, open(local_file_path, 'wb') as outf:\n",
    "            print(f\"Extracting file {file}\")\n",
    "            shutil.copyfileobj(f_in, outf)\n",
    "            os.remove(local_file_path + \".gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Anserini Index\n",
    "This may take a while... We are copying the procedure from here: https://github.com/castorini/anserini/blob/master/docs/experiments-msmarco-doc.md.\n",
    "\n",
    "- You will not receive any feedback on the output while the indexing is running. You may chack the progress by running `ls -lah` on the index folder and check if the files are increasing in size.\n",
    "- Alternatively, run the script manually (don't forget to set `JAVA_HOME`) and have some feedback on the terminal. As a sanity check, the index must contain 3,213,835 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T23:25:16.091889Z",
     "start_time": "2020-04-02T23:20:40.758074Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess, os\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "my_env = os.environ.copy()\n",
    "my_env[\"JAVA_HOME\"] = f\"{home}/.sdkman/candidates/java/11.0.6.hs-adpt\"  #Set right JAVA version\n",
    "\n",
    "command = [\n",
    "    \"sh\", f\"{anserini_path}/target/appassembler/bin/IndexCollection\",  # Invoke Anserini Indexer\n",
    "    \"-collection\", \"TrecCollection\", # Define type of collection (TREC)\n",
    "    \"-generator\", \"LuceneDocumentGenerator\",   # Define type of indice to generate\n",
    "    \"-threads\", str(n_threads),  # Number of threads to use to index\n",
    "    \"-input\", get_path(\"docs/\"),  # File with documents\n",
    "    \"-index\", get_path(\"lucene-index.msmarco-doc.pos+docvectors+rawdocs\"),  # Where to store the index\n",
    "    \"-storePositions\", \"-storeDocvectors\", \"-storeRawDocs\"  # Extra options\n",
    "]\n",
    "\n",
    "# Nothing will output to the shell. You may check progress by running \"ls -lah\" on the idex folder above.\n",
    "# Alternatively, you can run the script manually on a terminal, so you can have some feedback on the indexing process.\n",
    "output = subprocess.run(command,\n",
    "                        stdout=subprocess.PIPE,\n",
    "                        stderr=subprocess.PIPE,\n",
    "                        text=True,\n",
    "                        env=my_env)\n",
    "\n",
    "# Write log to disk.\n",
    "if not os.path.isdir(get_path(\"logs\")):\n",
    "    os.makedirs(get_path(\"logs\"))\n",
    "with open(get_path(\"logs/indexing.log\"), 'w') as f:\n",
    "    f.write(output.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Terrier Index\n",
    "This may take a while... We are copying the procedure from here: https://github.com/castorini/anserini/blob/master/docs/experiments-msmarco-doc.md.\n",
    "\n",
    "- You will not receive any feedback on the output while the indexing is running. You may chack the progress by running `ls -lah` on the index folder and check if the files are increasing in size.\n",
    "- Alternatively, run the script manually (don't forget to set `JAVA_HOME`) and have some feedback on the terminal. As a sanity check, the index must contain 3,213,835 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T22:09:08.774817Z",
     "start_time": "2020-04-16T22:09:08.771700Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/home/arthur/.sdkman/candidates/java/8.0.242-open\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T22:16:02.647980Z",
     "start_time": "2020-04-16T22:15:35.985935Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyjnius\n",
      "  Cloning https://github.com/cmacdonald/pyjnius.git to /tmp/pip-install-2yq1ea12/pyjnius\n",
      "  Running command git clone -q https://github.com/cmacdonald/pyjnius.git /tmp/pip-install-2yq1ea12/pyjnius\n",
      "Requirement already satisfied, skipping upgrade: six>=1.7.0 in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from pyjnius) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: cython in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from pyjnius) (0.29.16)\n",
      "Building wheels for collected packages: pyjnius\n",
      "  Building wheel for pyjnius (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyjnius: filename=pyjnius-1.2.2.dev0-cp37-cp37m-linux_x86_64.whl size=930840 sha256=e228716b9a53300fdf75efe61e8d227a901a393ffb030018c8f5d879d57b43d7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6vvn80gd/wheels/29/73/8d/b79a41d1e7c7d27e7b0c76064b52022fa33df4509296b444cc\n",
      "Successfully built pyjnius\n",
      "Installing collected packages: pyjnius\n",
      "  Attempting uninstall: pyjnius\n",
      "    Found existing installation: pyjnius 1.2.2.dev0\n",
      "    Uninstalling pyjnius-1.2.2.dev0:\n",
      "      Successfully uninstalled pyjnius-1.2.2.dev0\n",
      "Successfully installed pyjnius-1.2.2.dev0\n",
      "Collecting python-terrier\n",
      "  Cloning https://github.com/terrier-org/pyterrier.git to /tmp/pip-install-ajsxacqj/python-terrier\n",
      "  Running command git clone -q https://github.com/terrier-org/pyterrier.git /tmp/pip-install-ajsxacqj/python-terrier\n",
      "Requirement already up-to-date: pyjnius==1.2.2.dev0 in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (1.2.2.dev0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from python-terrier) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from python-terrier) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: wget in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied, skipping upgrade: pytrec_eval in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from python-terrier) (0.4)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from python-terrier) (4.44.1)\n",
      "Requirement already satisfied, skipping upgrade: cython in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from pyjnius==1.2.2.dev0) (0.29.16)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.7.0 in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from pyjnius==1.2.2.dev0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from pandas->python-terrier) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /ssd/home/arthur/miniconda3/envs/bert4IR/lib/python3.7/site-packages (from pandas->python-terrier) (2.8.1)\n",
      "Building wheels for collected packages: python-terrier\n",
      "  Building wheel for python-terrier (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-terrier: filename=python_terrier-0.1.3-py3-none-any.whl size=18011 sha256=d0243c940c6a390928e888a5ae9fbd3a1b7bea368a6c76a412d6144e7c38e4ca\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-52f5odds/wheels/61/12/f7/d3c3d17f72ab9ad1c5d510a0d6bd1612023e01fa0e07f01059\n",
      "Successfully built python-terrier\n",
      "Installing collected packages: python-terrier\n",
      "  Attempting uninstall: python-terrier\n",
      "    Found existing installation: python-terrier 0.1.3\n",
      "    Uninstalling python-terrier-0.1.3:\n",
      "      Successfully uninstalled python-terrier-0.1.3\n",
      "Successfully installed python-terrier-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/cmacdonald/pyjnius.git#egg=pyjnius\n",
    "!pip install --upgrade git+https://github.com/terrier-org/pyterrier.git#egg=python-terrier pyjnius==1.2.2.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T23:13:14.969310Z",
     "start_time": "2020-04-16T22:18:19.557556Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "pt.init(mem=16384)\n",
    "index_path = get_path(\"terrier-index\")\n",
    "indexer = pt.TRECCollectionIndexer(index_path)\n",
    "index_properies = {\"block.indexing\":\"true\", \"invertedfile.lexiconscanner\":\"pointers\"}\n",
    "index = indexer.index(get_path(\"docs/msmarco-docs.trec\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Bert4IR)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
